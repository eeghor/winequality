{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdata = pd.read_csv('data/Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RED wines: 1599 samples\n",
      "\n",
      "ratings: [(5, 681), (6, 638), (7, 199), (4, 53), (8, 18), (3, 10)]\n",
      "simplified ratings: [(1, 1319), (2, 217), (0, 63)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        16\n",
      "          1       0.90      0.97      0.93       338\n",
      "          2       0.69      0.52      0.59        46\n",
      "\n",
      "avg / total       0.84      0.88      0.85       400\n",
      "\n",
      "                 feature    weight\n",
      "0    free_sulfur_dioxide  0.249560\n",
      "1   total_sulfur_dioxide  0.095539\n",
      "2                density  0.079756\n",
      "3            citric_acid  0.078828\n",
      "4                     pH  0.078718\n",
      "5          fixed_acidity  0.075543\n",
      "6                alcohol  0.073263\n",
      "7       volatile_acidity  0.071252\n",
      "8              sulphates  0.067746\n",
      "9         residual_sugar  0.066736\n",
      "10             chlorides  0.063059\n",
      "\n",
      "WHITE wines: 4898 samples\n",
      "\n",
      "ratings: [(6, 2198), (5, 1457), (7, 880), (8, 175), (4, 163), (3, 20), (9, 5)]\n",
      "simplified ratings: [(1, 3655), (2, 1060), (0, 183)]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.14      0.24        36\n",
      "          1       0.85      0.97      0.90       919\n",
      "          2       0.84      0.51      0.64       270\n",
      "\n",
      "avg / total       0.85      0.85      0.83      1225\n",
      "\n",
      "                 feature    weight\n",
      "0              chlorides  0.132126\n",
      "1          fixed_acidity  0.130155\n",
      "2   total_sulfur_dioxide  0.106006\n",
      "3       volatile_acidity  0.096238\n",
      "4    free_sulfur_dioxide  0.090031\n",
      "5                     pH  0.083127\n",
      "6              sulphates  0.081889\n",
      "7            citric_acid  0.073449\n",
      "8         residual_sugar  0.071523\n",
      "9                alcohol  0.070675\n",
      "10               density  0.064782\n"
     ]
    }
   ],
   "source": [
    "def simplified_quality(q):\n",
    "    \n",
    "    if q <= 4:\n",
    "        return 0\n",
    "    elif q <= 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "for style in 'red white'.split():\n",
    "    \n",
    "    X = wdata[wdata['style'] == style].drop(['style','quality'], axis=1)\n",
    "    y = wdata[wdata['style'] == style]['quality']\n",
    "    \n",
    "    print(f'\\n{style.upper()} wines: {len(X)} samples\\n')\n",
    "    \n",
    "    print(f'ratings: {Counter(y).most_common()}')\n",
    "    \n",
    "    y = y.apply(simplified_quality)\n",
    "    \n",
    "    print(f'simplified ratings: {Counter(y).most_common()}')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=471)\n",
    "\n",
    "    pipe = make_pipeline(Normalizer(), PCA(), RandomForestClassifier(n_estimators=100, \n",
    "                                                                     class_weight='balanced'))\n",
    "\n",
    "    parameters = {'randomforestclassifier__n_estimators': [50, 200, 400],\n",
    "                 'randomforestclassifier__max_depth': [None, 2, 3, 4]}\n",
    "\n",
    "    clf = GridSearchCV(pipe, parameters)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    yh = clf.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, yh))\n",
    "\n",
    "    ranked_features = sorted([(f, im) for f, im in zip(X_train.columns, \n",
    "                 clf.best_estimator_.named_steps['randomforestclassifier'].feature_importances_)],\n",
    "       key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(pd.DataFrame.from_records(ranked_features, columns=['feature', 'weight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
